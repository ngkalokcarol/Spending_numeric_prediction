{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230a46e5",
   "metadata": {},
   "source": [
    "### Use numeric prediction techniques to build a predictive model for the HW3.xlsx dataset. This dataset is provided on the course website and contains data about whether or not different consumers made a purchase in response to a test mailing of a certain catalog and, in case of a purchase, how much money each consumer spent. The data file has a brief description of all the attributes in a separate worksheet. Note that this dataset has two possible outcome variables: Purchase (0/1 value: whether or not the purchase was made) and Spending (numeric value: amount spent).\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "(a) Build numeric prediction models that predict Spending based on the other available customer information (obviously, not including the Purchase attribute among the inputs!). Use linear regression, k-NN, regression tree, SVM regreesion and Neural Network and ensembling models. Briefly discuss your explorations and present the best result (best predictive model) for each of these techniques. Compare the techniques; which of them provides the best predictive performance? Please make sure you use best practices for predictive modeling. (I.e., do you need to set which hyper-parameter? Normalize?)\n",
    "\n",
    "(b) As a variation on this exercise, create a separate “restricted” dataset (i.e., a subset of the original dataset), which includes only purchase records (i.e., where Purchase = 1). Build numeric prediction models to predict Spending for this restricted dataset. All the same requirements as for task (a) apply.\n",
    "\n",
    "(c) For each predictive modeling technique, discuss the predictive performance differences between the models built for task (a) vs. task (b): which models exhibit better predictive performance? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54e224",
   "metadata": {},
   "source": [
    "### Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ea4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score\n",
    "from sklearn import preprocessing \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.model_selection import GridSearchCV, KFold,train_test_split, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMClassifier \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f90ac7",
   "metadata": {},
   "source": [
    "### Loading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba53e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"HW3.xlsx\", sheet_name = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78660aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>3662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>2900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3883</td>\n",
       "      <td>3914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_number  US  source_a  source_c  source_b  source_d  source_e  \\\n",
       "0                1   1         0         0         1         0         0   \n",
       "1                2   1         0         0         0         0         1   \n",
       "2                3   1         0         0         0         0         0   \n",
       "3                4   1         0         1         0         0         0   \n",
       "4                5   1         0         1         0         0         0   \n",
       "\n",
       "   source_m  source_o  source_h  ...  source_x  source_w  Freq  \\\n",
       "0         0         0         0  ...         0         0     2   \n",
       "1         0         0         0  ...         0         0     0   \n",
       "2         0         0         0  ...         0         0     2   \n",
       "3         0         0         0  ...         0         0     1   \n",
       "4         0         0         0  ...         0         0     1   \n",
       "\n",
       "   last_update_days_ago  1st_update_days_ago  Web order  Gender=male  \\\n",
       "0                  3662                 3662          1            0   \n",
       "1                  2900                 2900          1            1   \n",
       "2                  3883                 3914          0            0   \n",
       "3                   829                  829          0            1   \n",
       "4                   869                  869          0            0   \n",
       "\n",
       "   Address_is_res  Purchase  Spending  \n",
       "0               1         1    127.87  \n",
       "1               0         0      0.00  \n",
       "2               0         1    127.48  \n",
       "3               0         0      0.00  \n",
       "4               0         0      0.00  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the Dataframe\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a9f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   sequence_number       2000 non-null   int64  \n",
      " 1   US                    2000 non-null   int64  \n",
      " 2   source_a              2000 non-null   int64  \n",
      " 3   source_c              2000 non-null   int64  \n",
      " 4   source_b              2000 non-null   int64  \n",
      " 5   source_d              2000 non-null   int64  \n",
      " 6   source_e              2000 non-null   int64  \n",
      " 7   source_m              2000 non-null   int64  \n",
      " 8   source_o              2000 non-null   int64  \n",
      " 9   source_h              2000 non-null   int64  \n",
      " 10  source_r              2000 non-null   int64  \n",
      " 11  source_s              2000 non-null   int64  \n",
      " 12  source_t              2000 non-null   int64  \n",
      " 13  source_u              2000 non-null   int64  \n",
      " 14  source_p              2000 non-null   int64  \n",
      " 15  source_x              2000 non-null   int64  \n",
      " 16  source_w              2000 non-null   int64  \n",
      " 17  Freq                  2000 non-null   int64  \n",
      " 18  last_update_days_ago  2000 non-null   int64  \n",
      " 19  1st_update_days_ago   2000 non-null   int64  \n",
      " 20  Web order             2000 non-null   int64  \n",
      " 21  Gender=male           2000 non-null   int64  \n",
      " 22  Address_is_res        2000 non-null   int64  \n",
      " 23  Purchase              2000 non-null   int64  \n",
      " 24  Spending              2000 non-null   float64\n",
      "dtypes: float64(1), int64(24)\n",
      "memory usage: 390.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cfc3a",
   "metadata": {},
   "source": [
    "Most of the variables in this dataset are binary. Some of the variables are continuous. There are no catagorical variables in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed57da76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>1.417000</td>\n",
       "      <td>2155.101000</td>\n",
       "      <td>2435.601500</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>102.560745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.380489</td>\n",
       "      <td>0.332495</td>\n",
       "      <td>0.229979</td>\n",
       "      <td>0.237546</td>\n",
       "      <td>0.199493</td>\n",
       "      <td>0.358138</td>\n",
       "      <td>0.12742</td>\n",
       "      <td>0.179983</td>\n",
       "      <td>0.223089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>1.405738</td>\n",
       "      <td>1141.302846</td>\n",
       "      <td>1077.872233</td>\n",
       "      <td>0.494617</td>\n",
       "      <td>0.499524</td>\n",
       "      <td>0.415024</td>\n",
       "      <td>0.500125</td>\n",
       "      <td>186.749816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "      <td>1671.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2280.000000</td>\n",
       "      <td>2721.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3139.250000</td>\n",
       "      <td>3353.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1500.060000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_number           US     source_a     source_c     source_b  \\\n",
       "count      2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean       1000.500000     0.824500     0.126500     0.056000     0.060000   \n",
       "std         577.494589     0.380489     0.332495     0.229979     0.237546   \n",
       "min           1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         500.750000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%        1000.500000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%        1500.250000     1.000000     0.000000     0.000000     0.000000   \n",
       "max        2000.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          source_d     source_e    source_m     source_o     source_h  ...  \\\n",
       "count  2000.000000  2000.000000  2000.00000  2000.000000  2000.000000  ...   \n",
       "mean      0.041500     0.151000     0.01650     0.033500     0.052500  ...   \n",
       "std       0.199493     0.358138     0.12742     0.179983     0.223089  ...   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.00000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.00000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.00000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.00000     1.000000     1.000000  ...   \n",
       "\n",
       "          source_x     source_w         Freq  last_update_days_ago  \\\n",
       "count  2000.000000  2000.000000  2000.000000           2000.000000   \n",
       "mean      0.018000     0.137500     1.417000           2155.101000   \n",
       "std       0.132984     0.344461     1.405738           1141.302846   \n",
       "min       0.000000     0.000000     0.000000              1.000000   \n",
       "25%       0.000000     0.000000     1.000000           1133.000000   \n",
       "50%       0.000000     0.000000     1.000000           2280.000000   \n",
       "75%       0.000000     0.000000     2.000000           3139.250000   \n",
       "max       1.000000     1.000000    15.000000           4188.000000   \n",
       "\n",
       "       1st_update_days_ago    Web order  Gender=male  Address_is_res  \\\n",
       "count          2000.000000  2000.000000  2000.000000     2000.000000   \n",
       "mean           2435.601500     0.426000     0.524500        0.221000   \n",
       "std            1077.872233     0.494617     0.499524        0.415024   \n",
       "min               1.000000     0.000000     0.000000        0.000000   \n",
       "25%            1671.250000     0.000000     0.000000        0.000000   \n",
       "50%            2721.000000     0.000000     1.000000        0.000000   \n",
       "75%            3353.000000     1.000000     1.000000        0.000000   \n",
       "max            4188.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "          Purchase     Spending  \n",
       "count  2000.000000  2000.000000  \n",
       "mean      0.500000   102.560745  \n",
       "std       0.500125   186.749816  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.500000     1.855000  \n",
       "75%       1.000000   152.532500  \n",
       "max       1.000000  1500.060000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of Data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b27fc",
   "metadata": {},
   "source": [
    "### Create train and test data\n",
    "I will use a train and test dataset with 80:20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d77559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating predictor and response variable\n",
    "\n",
    "x = df.drop(['Purchase', 'Spending'], axis = 1)\n",
    "y = df['Spending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977c898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667eade",
   "metadata": {},
   "source": [
    "### Normalization using StandardScale\n",
    "StandardScaler will normalize the data with mean = 0 and SD = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb885bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = standardscaler.fit_transform(X_train) \n",
    "X_test = standardscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de881e02",
   "metadata": {},
   "source": [
    "### Score Metrics\n",
    "\n",
    "We will use Mean Squared Error for Score metrics as the evaulation of performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80a2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define score metrics for parameters optimization and model selection\n",
    "score = 'neg_mean_squared_error'\n",
    "\n",
    "# Inner and outer CV for models - 3 Folds\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=10)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7889d5d",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e60ec273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Parameters for lr gridsearch\n",
    "lr_grid = {\"fit_intercept\":[True,False], \"normalize\":[True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "076b76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_g = GridSearchCV(lr, lr_grid, scoring = score, cv = inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f79f24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = cross_val_score(lr_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "lr_scores = lr_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9db9e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Parameters for knn gridsearch\n",
    "knn_grid = {'n_neighbors':list(range(3,15)),\n",
    "            'weights': ['uniform','distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cf28f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_g = GridSearchCV(knn, knn_grid, scoring = score, cv = inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa23f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score = cross_val_score(knn_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "knn_scores = knn_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6cb1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Parameters for dt gridsearch\n",
    "dt_grid = {'max_depth' : list(range(3,15)),\n",
    "           'min_samples_split' : list(range(2,10)),\n",
    "           'min_samples_leaf': list(range(1,5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa296143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_g = GridSearchCV(dt, dt_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "dt_score = cross_val_score(dt_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "dt_scores = dt_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74b69444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm = SVR()\n",
    "\n",
    "# Parameters for svm gridsearch\n",
    "svm_grid = {'kernel': ['rbf'],\n",
    "            'gamma': [1,0.1,0.01,0.001],\n",
    "            'C': [0.001,0.01,0.1,1,10,100,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d4558b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_g = GridSearchCV(svm, svm_grid, scoring = score, cv = inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd91a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score = cross_val_score(svm_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "svm_scores = svm_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebcf0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "nn = MLPRegressor()\n",
    "\n",
    "# Parameters for nn gridsearch\n",
    "nn_grid = {'hidden_layer_sizes':[(1,),(50,)], \n",
    "           'activation':['identity','logistic','tanh','relu']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f36f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_g = GridSearchCV(nn, nn_grid, scoring = score, cv = inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8137ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_score = cross_val_score(nn_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "nn_scores = nn_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5efc4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Parameters for xgb gridsearch\n",
    "xgb_grid = {'max_depth': [5,7,8,9],\n",
    "            'learning_rate': [0.1, 0.2, 0.3],\n",
    "            'colsample_bytree': [0.4, 0.8],\n",
    "            'min_child_weight': [1,5,10],\n",
    "            'gamma': [0.5, 1, 1.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7352e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_g = GridSearchCV(xgb, xgb_grid, scoring = score, cv = inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d10bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score = cross_val_score(xgb_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "xgb_scores = xgb_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9afcc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE of Linear Regression: -17523.49968853053\n",
      "Mean MSE of KNN: -23471.77351331543\n",
      "Mean MSE of Decision Tree: -21685.779046653013\n",
      "Mean MSE of SVM: -16866.141249547472\n",
      "Mean MSE of Neural Networks: -26160.399030528144\n",
      "Mean MSE of XGBoost: -18106.44558297301\n"
     ]
    }
   ],
   "source": [
    "print('Mean MSE of Linear Regression:', lr_scores)\n",
    "print('Mean MSE of KNN:', knn_scores)\n",
    "print('Mean MSE of Decision Tree:', dt_scores)\n",
    "print('Mean MSE of SVM:', svm_scores)\n",
    "print('Mean MSE of Neural Networks:', nn_scores)\n",
    "print('Mean MSE of XGBoost:', xgb_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ba401",
   "metadata": {},
   "source": [
    "SVM got the lowest mean squared error. We will run the best parameters and best scores for further tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4599e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameter\n",
    "\n",
    "best_lr = lr_g.fit(X_train, y_train)\n",
    "best_knn = knn_g.fit(X_train, y_train)\n",
    "best_dt = dt_g.fit(X_train, y_train)\n",
    "best_svm = svm_g.fit(X_train, y_train)\n",
    "best_nn = nn_g.fit(X_train, y_train)\n",
    "best_xgb = xgb_g.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bcd5e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR para: {'fit_intercept': True, 'normalize': True}\n",
      "Best KNN para: {'n_neighbors': 11, 'weights': 'distance'}\n",
      "Best DT para: {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 7}\n",
      "Best SVM para: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best NN para: {'activation': 'identity', 'hidden_layer_sizes': (50,)}\n",
      "Best XGB para: {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 5}\n"
     ]
    }
   ],
   "source": [
    "# optimized hyperparameters\n",
    "print('Best LR para:', best_lr.best_params_)\n",
    "print('Best KNN para:', best_knn.best_params_)\n",
    "print('Best DT para:', best_dt.best_params_)\n",
    "print('Best SVM para:', best_svm.best_params_)\n",
    "print('Best NN para:', best_nn.best_params_)\n",
    "print('Best XGB para:', best_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4120b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR score: -17362.19752321727\n",
      "Best KNN score: -23523.71048133974\n",
      "Best DT score: -19184.45571991688\n",
      "Best SVM score: -16507.730280342807\n",
      "Best NN score: -24173.248539377135\n",
      "Best XGB score: -16996.76105463757\n"
     ]
    }
   ],
   "source": [
    "# best model scores\n",
    "print('Best LR score:', best_lr.best_score_)\n",
    "print('Best KNN score:', best_knn.best_score_)\n",
    "print('Best DT score:', best_dt.best_score_)\n",
    "print('Best SVM score:', best_svm.best_score_)\n",
    "print('Best NN score:', best_nn.best_score_)\n",
    "print('Best XGB score:', best_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375165b",
   "metadata": {},
   "source": [
    "Best model with optimized parameter is XGBoost, we will use it on test set to run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57bc0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for predictions\n",
    "y_pred = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "061dd3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.5023386033806\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the best model with MSE on test set\n",
    "\n",
    "best_svm_mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(best_xgb_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd3eb4",
   "metadata": {},
   "source": [
    "The final best XGB Model with adjusted parameters have a \n",
    "RMSE of 120.3323 on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a4c89",
   "metadata": {},
   "source": [
    "## Task (b) Create a new dataset with only records for \"Purchase =1\" and build the models to compare the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564d2fa",
   "metadata": {},
   "source": [
    "### Filter the original dataset to include only (Purchase = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e90fb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Purchase']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998c48",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b265ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df2.drop(['Purchase','Spending'], axis=1)\n",
    "y = df2['Spending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66209f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00affce6",
   "metadata": {},
   "source": [
    "### Normalization using StandardScale like (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b75495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler = preprocessing.StandardScaler().fit(X_train) \n",
    "X_train = standardscaler.fit_transform(X_train) \n",
    "X_test = standardscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33263afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Parameters for lr gridsearch\n",
    "lr_grid = {\"fit_intercept\":[True,False], \"normalize\":[True,False]}\n",
    "\n",
    "# Inner and outer CV\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=10)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=11)\n",
    "\n",
    "# Define score metrics for parameters optimization and model selection\n",
    "score = 'neg_mean_squared_error'\n",
    "\n",
    "lr_g = GridSearchCV(lr, lr_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "lr_score = cross_val_score(lr_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "lr_scores = lr_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebd258d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Parameters for knn gridsearch\n",
    "knn_grid = {'n_neighbors':list(range(3,15)),\n",
    "            'weights': ['uniform','distance']}\n",
    "\n",
    "knn_g = GridSearchCV(knn, knn_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "knn_score = cross_val_score(knn_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "knn_scores = knn_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe139990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Parameters for dt gridsearch\n",
    "dt_grid = {'max_depth' : list(range(13,15)),\n",
    "           'min_samples_split' : list(range(2,4)),\n",
    "           'min_samples_leaf': list(range(1,2))}\n",
    "\n",
    "dt_g = GridSearchCV(dt, dt_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "dt_score = cross_val_score(dt_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "dt_scores = dt_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb99b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm = SVR()\n",
    "\n",
    "# Parameters for svm gridsearch\n",
    "svm_grid = {'kernel': ['rbf'],\n",
    "            'gamma': [1,0.1,0.01,0.001],\n",
    "            'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "svm_g = GridSearchCV(svm, svm_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "svm_score = cross_val_score(svm_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "svm_scores = svm_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3167e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "nn = MLPRegressor()\n",
    "\n",
    "# Parameters for nn gridsearch\n",
    "nn_grid = {'hidden_layer_sizes':[(1,),(50,)], \n",
    "           'activation':['identity','logistic','tanh','relu']}\n",
    "\n",
    "nn_g = GridSearchCV(nn, nn_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "nn_score = cross_val_score(nn_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "nn_scores = nn_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a6d12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Parameters for xgb gridsearch\n",
    "xgb_grid = {'max_depth': [3,4,5],\n",
    "            'learning_rate': [0.1, 0.2, 0.3],\n",
    "            'colsample_bytree': [0.4, 0.8],\n",
    "            'min_child_weight': [1,5,10],\n",
    "            'gamma': [0.5, 1, 1.5]}\n",
    "\n",
    "xgb_g = GridSearchCV(xgb, xgb_grid, scoring = score, cv = inner_cv)\n",
    "\n",
    "xgb_score = cross_val_score(xgb_g, X=X_train, y=y_train, scoring = score, cv=outer_cv)\n",
    "xgb_scores = xgb_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ae1c46cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE of Linear Regression: -28689.20545500593\n",
      "Mean MSE of KNN: -37802.45814780904\n",
      "Mean MSE of Decision Tree: -55308.69564453004\n",
      "Mean MSE of SVM: -28945.809591083962\n",
      "Mean MSE of Neural Networks: -68418.53273716995\n",
      "Mean MSE of XGBoost: -33888.648141369216\n"
     ]
    }
   ],
   "source": [
    "print('Mean MSE of Linear Regression:', lr_scores)\n",
    "print('Mean MSE of KNN:', knn_scores)\n",
    "print('Mean MSE of Decision Tree:', dt_scores)\n",
    "print('Mean MSE of SVM:', svm_scores)\n",
    "print('Mean MSE of Neural Networks:', nn_scores)\n",
    "print('Mean MSE of XGBoost:', xgb_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b16c6",
   "metadata": {},
   "source": [
    "Linear Regression and SVM got the best performance, now we will optimize parameters and best scores to see which one we should choose for test set and prediction of this dataset with only records of (purchase = 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b998d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameter\n",
    "\n",
    "best_lr = lr_g.fit(X_train, y_train)\n",
    "best_knn = knn_g.fit(X_train, y_train)\n",
    "best_dt = dt_g.fit(X_train, y_train)\n",
    "best_svm = svm_g.fit(X_train, y_train)\n",
    "best_nn = nn_g.fit(X_train, y_train)\n",
    "best_xgb = xgb_g.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b971d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR para: {'fit_intercept': True, 'normalize': False}\n",
      "Best KNN para: {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "Best DT para: {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best SVM para: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best NN para: {'activation': 'relu', 'hidden_layer_sizes': (50,)}\n",
      "Best XGB para: {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 10}\n"
     ]
    }
   ],
   "source": [
    "# optimized hyperparameters\n",
    "print('Best LR para:', best_lr.best_params_)\n",
    "print('Best KNN para:', best_knn.best_params_)\n",
    "print('Best DT para:', best_dt.best_params_)\n",
    "print('Best SVM para:', best_svm.best_params_)\n",
    "print('Best NN para:', best_nn.best_params_)\n",
    "print('Best XGB para:', best_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5bcc33ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR score: -27499.283218975794\n",
      "Best KNN score: -30731.528298583333\n",
      "Best DT score: -44882.71063830598\n",
      "Best SVM score: -25984.87576312307\n",
      "Best NN score: -70157.694948203\n",
      "Best XGB score: -28899.743754322568\n"
     ]
    }
   ],
   "source": [
    "# best model scores\n",
    "print('Best LR score:', best_lr.best_score_)\n",
    "print('Best KNN score:', best_knn.best_score_)\n",
    "print('Best DT score:', best_dt.best_score_)\n",
    "print('Best SVM score:', best_svm.best_score_)\n",
    "print('Best NN score:', best_nn.best_score_)\n",
    "print('Best XGB score:', best_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a29cbd",
   "metadata": {},
   "source": [
    "Best model with optimized parameter is SVM, we will use it on test set to run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e887f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling for prediction\n",
    "\n",
    "y_pred = best_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5735ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.18814970327554\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the best model with MSE on test set\n",
    "\n",
    "best_svm_mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(best_svm_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f21b33",
   "metadata": {},
   "source": [
    "### Task(c)\n",
    "### For each predictive modeling technique, discuss the predictive performance differences between the models built for task (a) vs. task (b): which models exhibit better predictive performance? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c07935",
   "metadata": {},
   "source": [
    "Linear Regression is 36% better in Task (A)\n",
    "\n",
    "KNN is 23% better in Task (A)\n",
    "\n",
    "DT is 57% better in Task (A)\n",
    "\n",
    "SVM is 36% better in Task (A)\n",
    "\n",
    "NN is 65% better in Task (A)\n",
    "\n",
    "XGB is 41% better in Task (A)\n",
    "\n",
    "Task (A) Performance VS Task (B) Performance\n",
    "\n",
    "Best LR score: -17362.19752321727\n",
    "\n",
    "Best KNN score: -23523.71048133974\n",
    "\n",
    "Best DT score: -19184.45571991688\n",
    "\n",
    "Best SVM score: -16507.730280342807\n",
    "\n",
    "Best NN score: -24173.248539377135\n",
    "\n",
    "Best XGB score: -16996.76105463757\n",
    "\n",
    "VS\n",
    "    \n",
    "Best LR score: -27499.283218975794\n",
    "\n",
    "Best KNN score: -30731.528298583333\n",
    "\n",
    "Best DT score: -44882.71063830598\n",
    "\n",
    "Best SVM score: -25984.87576312307\n",
    "\n",
    "Best NN score: -70157.694948203\n",
    "\n",
    "Best XGB score: -28899.743754322568\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82dfc2",
   "metadata": {},
   "source": [
    "### Evaulation \n",
    "\n",
    "In task (ii), we filtered out the purchase class of 0, so the training dataset is greatly reduced. All the mean squared errors are much higher in Task (ii) model than task (i) (when filtered out data without purchase). That means purchase is a very important feature to this model, and in the future we need to pay attention to all the features to make sure the same problem will not happen, especially for very heavy weighted features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d04c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
